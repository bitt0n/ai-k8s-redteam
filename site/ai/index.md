# AI Pentesting Track

- Threat models for LLM apps (prompt injection, tool abuse, jailbreaks).
- RAG weak points: data poisoning, canary exfil, retrieval drift.
- Vector store health checks: secrets/PII leakage, metadata risks.
- Offline red-team harness: YAML-driven test cases; pluggable model adapters.
